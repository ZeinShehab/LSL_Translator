{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "igMyGnjE9hEp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\zeins\\anaconda3\\envs\\lsl\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2HDvhIu9hEr"
      },
      "source": [
        "# Specify each path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9NvZP2Zn9hEy"
      },
      "outputs": [],
      "source": [
        "data_directory = \"../../../data/\"\n",
        "train_dataset = f'{data_directory}augmented_gestures_train_new.csv'\n",
        "test_dataset = f'{data_directory}augmented_gestures_test_new.csv'\n",
        "model_save_path = './gesture_classifier.keras'\n",
        "tflite_save_path = './gesture_classifier.tflite'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5oMH7x19hEz"
      },
      "source": [
        "# Set number of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "du4kodXL9hEz"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 42\n",
        "NUM_CLASSES = 2\n",
        "NUM_SEQUENCE_FRAMES = 10\n",
        "MULTI_HAND_LANDMARKS = 126\n",
        "FEATURE_DIM = MULTI_HAND_LANDMARKS * NUM_SEQUENCE_FRAMES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjnL0uso9hEz"
      },
      "source": [
        "# Dataset reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QT5ZqtEz9hE0"
      },
      "outputs": [],
      "source": [
        "X_train = np.loadtxt(train_dataset, delimiter=',', dtype='float32', usecols=list(range(1, FEATURE_DIM + 1)))\n",
        "X_test_data = np.loadtxt(test_dataset, delimiter=',', dtype='float32', usecols=list(range(1, FEATURE_DIM + 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QmoKFsp49hE0"
      },
      "outputs": [],
      "source": [
        "y_train = np.loadtxt(train_dataset, delimiter=',', dtype='int32', usecols=(0))\n",
        "y_test_data = np.loadtxt(test_dataset, delimiter=',', dtype='int32', usecols=(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test, X_valid, y_test, y_valid = train_test_split(X_test_data, y_test_data, train_size=0.75, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n"
          ]
        }
      ],
      "source": [
        "print(np.unique(y_train))\n",
        "print(np.unique(y_test))\n",
        "print(np.unique(y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(220, 1260)\n",
            "(220,)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxK_lETT9hE0"
      },
      "source": [
        "# Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vHBmUf1t9hE1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\zeins\\anaconda3\\envs\\lsl\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input((FEATURE_DIM, )),\n",
        "    # tf.keras.layers.BatchNormalization(),  # Normalizes input features\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),  # Dropout for regularization\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.3),  # Dropout for regularization\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),  # Dropout for regularization\n",
        "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')  # Output layer with 5 units\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    model_save_path, verbose=1, save_weights_only=False)\n",
        "# Callback for early stopping\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\zeins\\anaconda3\\envs\\lsl\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Model compilation\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "WARNING:tensorflow:From c:\\Users\\zeins\\anaconda3\\envs\\lsl\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\zeins\\anaconda3\\envs\\lsl\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
            "\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7829 - accuracy: 0.4688\n",
            "Epoch 1: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.7777 - accuracy: 0.5045 - val_loss: 0.6646 - val_accuracy: 0.5152\n",
            "Epoch 2/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.7075 - accuracy: 0.4688\n",
            "Epoch 2: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.7089 - accuracy: 0.4955 - val_loss: 0.6673 - val_accuracy: 0.4848\n",
            "Epoch 3/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6944 - accuracy: 0.5234\n",
            "Epoch 3: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.6841 - accuracy: 0.5591 - val_loss: 0.6857 - val_accuracy: 0.5152\n",
            "Epoch 4/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6758 - accuracy: 0.5703\n",
            "Epoch 4: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.6727 - accuracy: 0.5864 - val_loss: 0.6632 - val_accuracy: 0.5152\n",
            "Epoch 5/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6755 - accuracy: 0.5781\n",
            "Epoch 5: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.6848 - accuracy: 0.5682 - val_loss: 0.6191 - val_accuracy: 1.0000\n",
            "Epoch 6/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6650 - accuracy: 0.5703\n",
            "Epoch 6: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.6710 - accuracy: 0.5636 - val_loss: 0.6064 - val_accuracy: 0.4848\n",
            "Epoch 7/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6491 - accuracy: 0.6250\n",
            "Epoch 7: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.6551 - accuracy: 0.6091 - val_loss: 0.5684 - val_accuracy: 1.0000\n",
            "Epoch 8/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6348 - accuracy: 0.6484\n",
            "Epoch 8: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.6278 - accuracy: 0.6591 - val_loss: 0.5637 - val_accuracy: 0.9697\n",
            "Epoch 9/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.6220 - accuracy: 0.6562\n",
            "Epoch 9: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.6375 - accuracy: 0.6591 - val_loss: 0.5332 - val_accuracy: 0.9697\n",
            "Epoch 10/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5928 - accuracy: 0.6953\n",
            "Epoch 10: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5879 - accuracy: 0.7045 - val_loss: 0.4927 - val_accuracy: 1.0000\n",
            "Epoch 11/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5597 - accuracy: 0.7422\n",
            "Epoch 11: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5401 - accuracy: 0.7364 - val_loss: 0.4579 - val_accuracy: 1.0000\n",
            "Epoch 12/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.5654 - accuracy: 0.6875\n",
            "Epoch 12: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5368 - accuracy: 0.7318 - val_loss: 0.3906 - val_accuracy: 1.0000\n",
            "Epoch 13/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4908 - accuracy: 0.7812\n",
            "Epoch 13: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.5107 - accuracy: 0.7455 - val_loss: 0.3514 - val_accuracy: 1.0000\n",
            "Epoch 14/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4279 - accuracy: 0.8594\n",
            "Epoch 14: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4235 - accuracy: 0.8545 - val_loss: 0.3330 - val_accuracy: 1.0000\n",
            "Epoch 15/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.4327 - accuracy: 0.8359\n",
            "Epoch 15: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4258 - accuracy: 0.8409 - val_loss: 0.2606 - val_accuracy: 1.0000\n",
            "Epoch 16/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3729 - accuracy: 0.8750\n",
            "Epoch 16: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.3698 - accuracy: 0.8682 - val_loss: 0.1945 - val_accuracy: 1.0000\n",
            "Epoch 17/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.3244 - accuracy: 0.9375\n",
            "Epoch 17: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.3106 - accuracy: 0.9318 - val_loss: 0.1769 - val_accuracy: 1.0000\n",
            "Epoch 18/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2441 - accuracy: 0.9688\n",
            "Epoch 18: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.2449 - accuracy: 0.9545 - val_loss: 0.1565 - val_accuracy: 1.0000\n",
            "Epoch 19/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2228 - accuracy: 0.9609\n",
            "Epoch 19: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.2371 - accuracy: 0.9545 - val_loss: 0.1163 - val_accuracy: 1.0000\n",
            "Epoch 20/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.2137 - accuracy: 0.9609\n",
            "Epoch 20: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1944 - accuracy: 0.9682 - val_loss: 0.0921 - val_accuracy: 1.0000\n",
            "Epoch 21/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1812 - accuracy: 0.9922\n",
            "Epoch 21: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1670 - accuracy: 0.9909 - val_loss: 0.0851 - val_accuracy: 1.0000\n",
            "Epoch 22/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1472 - accuracy: 0.9844\n",
            "Epoch 22: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.1373 - accuracy: 0.9818 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
            "Epoch 23/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1104 - accuracy: 0.9766\n",
            "Epoch 23: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.1068 - accuracy: 0.9773 - val_loss: 0.0301 - val_accuracy: 1.0000\n",
            "Epoch 24/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.1028 - accuracy: 0.9844\n",
            "Epoch 24: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0932 - accuracy: 0.9818 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
            "Epoch 25/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0788 - accuracy: 0.9922\n",
            "Epoch 25: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0900 - accuracy: 0.9864 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 26/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0536 - accuracy: 0.9922\n",
            "Epoch 26: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0514 - accuracy: 0.9909 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
            "Epoch 27/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0559 - accuracy: 0.9844\n",
            "Epoch 27: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0515 - accuracy: 0.9864 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 28/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0353 - accuracy: 1.0000\n",
            "Epoch 28: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
            "Epoch 29/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0372 - accuracy: 1.0000\n",
            "Epoch 29: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0360 - accuracy: 0.9955 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
            "Epoch 30/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0475 - accuracy: 0.9922\n",
            "Epoch 30: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0413 - accuracy: 0.9909 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 31/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0209 - accuracy: 1.0000\n",
            "Epoch 31: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0255 - accuracy: 0.9955 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 32/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0211 - accuracy: 1.0000\n",
            "Epoch 32: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0227 - accuracy: 0.9955 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 33/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0238 - accuracy: 1.0000\n",
            "Epoch 33: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 34/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0185 - accuracy: 0.9922\n",
            "Epoch 34: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0193 - accuracy: 0.9955 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 35/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 35: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 36/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0159 - accuracy: 0.9922\n",
            "Epoch 36: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0180 - accuracy: 0.9955 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 37/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0132 - accuracy: 1.0000\n",
            "Epoch 37: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 38/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0124 - accuracy: 1.0000\n",
            "Epoch 38: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0165 - accuracy: 0.9955 - val_loss: 9.2483e-04 - val_accuracy: 1.0000\n",
            "Epoch 39/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0142 - accuracy: 1.0000\n",
            "Epoch 39: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 7.4548e-04 - val_accuracy: 1.0000\n",
            "Epoch 40/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 40: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 7.9664e-04 - val_accuracy: 1.0000\n",
            "Epoch 41/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 41: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 42/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0075 - accuracy: 1.0000\n",
            "Epoch 42: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 43/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 43: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 7.9995e-04 - val_accuracy: 1.0000\n",
            "Epoch 44/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 44: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 4.7504e-04 - val_accuracy: 1.0000\n",
            "Epoch 45/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 45: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.1247e-04 - val_accuracy: 1.0000\n",
            "Epoch 46/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 46: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.5547e-04 - val_accuracy: 1.0000\n",
            "Epoch 47/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 47: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 2.2436e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0128 - accuracy: 1.0000\n",
            "Epoch 48: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.7960e-04 - val_accuracy: 1.0000\n",
            "Epoch 49/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 49: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.5853e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 50: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.1419e-04 - val_accuracy: 1.0000\n",
            "Epoch 51/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 51: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 3.0470e-04 - val_accuracy: 1.0000\n",
            "Epoch 52/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 52: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.9649e-04 - val_accuracy: 1.0000\n",
            "Epoch 53/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 53: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3987e-04 - val_accuracy: 1.0000\n",
            "Epoch 54/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 54: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.1663e-04 - val_accuracy: 1.0000\n",
            "Epoch 55/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 55: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0413e-04 - val_accuracy: 1.0000\n",
            "Epoch 56/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 56: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 9.6695e-05 - val_accuracy: 1.0000\n",
            "Epoch 57/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 57: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 8.9984e-05 - val_accuracy: 1.0000\n",
            "Epoch 58/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 58: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 8.5996e-05 - val_accuracy: 1.0000\n",
            "Epoch 59/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 59: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 9.9125e-05 - val_accuracy: 1.0000\n",
            "Epoch 60/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 60: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2526e-04 - val_accuracy: 1.0000\n",
            "Epoch 61/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 61: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.2942e-04 - val_accuracy: 1.0000\n",
            "Epoch 62/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 62: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.1962e-04 - val_accuracy: 1.0000\n",
            "Epoch 63/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 63: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.1029e-04 - val_accuracy: 1.0000\n",
            "Epoch 64/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 64: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0171e-04 - val_accuracy: 1.0000\n",
            "Epoch 65/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 65: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 9.4506e-05 - val_accuracy: 1.0000\n",
            "Epoch 66/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 66: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 9.7381e-05 - val_accuracy: 1.0000\n",
            "Epoch 67/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 67: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.0290e-04 - val_accuracy: 1.0000\n",
            "Epoch 68/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 68: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0669e-04 - val_accuracy: 1.0000\n",
            "Epoch 69/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 69: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.0824e-04 - val_accuracy: 1.0000\n",
            "Epoch 70/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 70: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 9.4186e-04 - accuracy: 1.0000 - val_loss: 1.0260e-04 - val_accuracy: 1.0000\n",
            "Epoch 71/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 71: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0057 - accuracy: 0.9955 - val_loss: 7.7471e-05 - val_accuracy: 1.0000\n",
            "Epoch 72/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 72: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 7.1815e-05 - val_accuracy: 1.0000\n",
            "Epoch 73/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 73: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 8.4111e-05 - val_accuracy: 1.0000\n",
            "Epoch 74/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 74: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 9.5484e-05 - val_accuracy: 1.0000\n",
            "Epoch 75/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 75: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 9.6990e-05 - val_accuracy: 1.0000\n",
            "Epoch 76/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 76: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 8.6899e-05 - val_accuracy: 1.0000\n",
            "Epoch 77/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 77: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 7.3618e-05 - val_accuracy: 1.0000\n",
            "Epoch 78/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 78: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 6.5830e-05 - val_accuracy: 1.0000\n",
            "Epoch 79/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 79: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 6.2174e-05 - val_accuracy: 1.0000\n",
            "Epoch 80/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 80: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 5.4795e-05 - val_accuracy: 1.0000\n",
            "Epoch 81/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.9396e-04 - accuracy: 1.0000\n",
            "Epoch 81: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.7758e-05 - val_accuracy: 1.0000\n",
            "Epoch 82/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6807e-04 - accuracy: 1.0000\n",
            "Epoch 82: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 6.6854e-04 - accuracy: 1.0000 - val_loss: 4.1776e-05 - val_accuracy: 1.0000\n",
            "Epoch 83/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 83: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 4.4290e-05 - val_accuracy: 1.0000\n",
            "Epoch 84/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.5525e-04 - accuracy: 1.0000\n",
            "Epoch 84: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 8.3849e-04 - accuracy: 1.0000 - val_loss: 4.6403e-05 - val_accuracy: 1.0000\n",
            "Epoch 85/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 85: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 4.6024e-05 - val_accuracy: 1.0000\n",
            "Epoch 86/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 8.3751e-04 - accuracy: 1.0000\n",
            "Epoch 86: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 6.4277e-04 - accuracy: 1.0000 - val_loss: 4.2498e-05 - val_accuracy: 1.0000\n",
            "Epoch 87/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.0460e-04 - accuracy: 1.0000\n",
            "Epoch 87: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 6.2508e-04 - accuracy: 1.0000 - val_loss: 3.7792e-05 - val_accuracy: 1.0000\n",
            "Epoch 88/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 88: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 8.9927e-04 - accuracy: 1.0000 - val_loss: 3.1517e-05 - val_accuracy: 1.0000\n",
            "Epoch 89/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 89: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.4004e-05 - val_accuracy: 1.0000\n",
            "Epoch 90/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.3552e-04 - accuracy: 1.0000\n",
            "Epoch 90: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 4.2696e-04 - accuracy: 1.0000 - val_loss: 1.9485e-05 - val_accuracy: 1.0000\n",
            "Epoch 91/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6800e-04 - accuracy: 1.0000\n",
            "Epoch 91: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 5.2714e-04 - accuracy: 1.0000 - val_loss: 1.6960e-05 - val_accuracy: 1.0000\n",
            "Epoch 92/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.8000e-04 - accuracy: 1.0000\n",
            "Epoch 92: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 6.4425e-04 - accuracy: 1.0000 - val_loss: 1.5515e-05 - val_accuracy: 1.0000\n",
            "Epoch 93/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6029e-04 - accuracy: 1.0000\n",
            "Epoch 93: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 5.6710e-04 - accuracy: 1.0000 - val_loss: 1.4431e-05 - val_accuracy: 1.0000\n",
            "Epoch 94/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.1054e-04 - accuracy: 1.0000\n",
            "Epoch 94: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 4.1388e-04 - accuracy: 1.0000 - val_loss: 1.3626e-05 - val_accuracy: 1.0000\n",
            "Epoch 95/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2134e-04 - accuracy: 1.0000\n",
            "Epoch 95: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.2557e-05 - val_accuracy: 1.0000\n",
            "Epoch 96/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0062e-04 - accuracy: 1.0000\n",
            "Epoch 96: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 6.8514e-04 - accuracy: 1.0000 - val_loss: 1.1704e-05 - val_accuracy: 1.0000\n",
            "Epoch 97/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.1183e-04 - accuracy: 1.0000\n",
            "Epoch 97: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 7.2774e-04 - accuracy: 1.0000 - val_loss: 1.1130e-05 - val_accuracy: 1.0000\n",
            "Epoch 98/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.7239e-04 - accuracy: 1.0000\n",
            "Epoch 98: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 7.3416e-04 - accuracy: 1.0000 - val_loss: 1.0675e-05 - val_accuracy: 1.0000\n",
            "Epoch 99/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.3311e-04 - accuracy: 1.0000\n",
            "Epoch 99: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 6.1715e-04 - accuracy: 1.0000 - val_loss: 1.0299e-05 - val_accuracy: 1.0000\n",
            "Epoch 100/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.2135e-04 - accuracy: 1.0000\n",
            "Epoch 100: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 8.6623e-04 - accuracy: 1.0000 - val_loss: 1.0042e-05 - val_accuracy: 1.0000\n",
            "Epoch 101/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.6491e-04 - accuracy: 1.0000\n",
            "Epoch 101: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 7.0235e-04 - accuracy: 1.0000 - val_loss: 9.7173e-06 - val_accuracy: 1.0000\n",
            "Epoch 102/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.4044e-04 - accuracy: 1.0000\n",
            "Epoch 102: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 5.3708e-04 - accuracy: 1.0000 - val_loss: 9.3308e-06 - val_accuracy: 1.0000\n",
            "Epoch 103/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5665e-04 - accuracy: 1.0000\n",
            "Epoch 103: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 8.4600e-04 - accuracy: 1.0000 - val_loss: 8.8973e-06 - val_accuracy: 1.0000\n",
            "Epoch 104/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 3.3775e-04 - accuracy: 1.0000\n",
            "Epoch 104: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 3.3599e-04 - accuracy: 1.0000 - val_loss: 8.5216e-06 - val_accuracy: 1.0000\n",
            "Epoch 105/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.6848e-04 - accuracy: 1.0000\n",
            "Epoch 105: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 4.8062e-04 - accuracy: 1.0000 - val_loss: 8.1279e-06 - val_accuracy: 1.0000\n",
            "Epoch 106/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.5339e-04 - accuracy: 1.0000\n",
            "Epoch 106: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 9.2759e-04 - accuracy: 1.0000 - val_loss: 8.2037e-06 - val_accuracy: 1.0000\n",
            "Epoch 107/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.5272e-04 - accuracy: 1.0000\n",
            "Epoch 107: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 3.2544e-04 - accuracy: 1.0000 - val_loss: 8.8684e-06 - val_accuracy: 1.0000\n",
            "Epoch 108/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0583e-04 - accuracy: 1.0000\n",
            "Epoch 108: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 5.8237e-04 - accuracy: 1.0000 - val_loss: 9.7317e-06 - val_accuracy: 1.0000\n",
            "Epoch 109/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.0279e-04 - accuracy: 1.0000\n",
            "Epoch 109: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 9.1068e-06 - val_accuracy: 1.0000\n",
            "Epoch 110/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 2.7548e-04 - accuracy: 1.0000\n",
            "Epoch 110: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 3.7785e-04 - accuracy: 1.0000 - val_loss: 8.0014e-06 - val_accuracy: 1.0000\n",
            "Epoch 111/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 111: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 8.7213e-04 - accuracy: 1.0000 - val_loss: 7.9617e-06 - val_accuracy: 1.0000\n",
            "Epoch 112/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.8795e-04 - accuracy: 1.0000\n",
            "Epoch 112: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 6.3938e-04 - accuracy: 1.0000 - val_loss: 8.0954e-06 - val_accuracy: 1.0000\n",
            "Epoch 113/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 113: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 8.7892e-04 - accuracy: 1.0000 - val_loss: 8.2977e-06 - val_accuracy: 1.0000\n",
            "Epoch 114/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.4216e-04 - accuracy: 1.0000\n",
            "Epoch 114: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 5.0879e-04 - accuracy: 1.0000 - val_loss: 8.4819e-06 - val_accuracy: 1.0000\n",
            "Epoch 115/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 115: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.1162e-05 - val_accuracy: 1.0000\n",
            "Epoch 116/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 116: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.6162e-05 - val_accuracy: 1.0000\n",
            "Epoch 117/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.0392e-04 - accuracy: 1.0000\n",
            "Epoch 117: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 7.1823e-04 - accuracy: 1.0000 - val_loss: 2.3220e-05 - val_accuracy: 1.0000\n",
            "Epoch 118/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 118: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6977e-05 - val_accuracy: 1.0000\n",
            "Epoch 119/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 119: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.3332e-05 - val_accuracy: 1.0000\n",
            "Epoch 120/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 4.2150e-04 - accuracy: 1.0000\n",
            "Epoch 120: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0037 - accuracy: 0.9955 - val_loss: 1.6176e-05 - val_accuracy: 1.0000\n",
            "Epoch 121/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 121: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.2488e-05 - val_accuracy: 1.0000\n",
            "Epoch 122/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 122: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2690e-05 - val_accuracy: 1.0000\n",
            "Epoch 123/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 5.4959e-04 - accuracy: 1.0000\n",
            "Epoch 123: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 6.8224e-04 - accuracy: 1.0000 - val_loss: 1.3749e-05 - val_accuracy: 1.0000\n",
            "Epoch 124/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 1.9402e-04 - accuracy: 1.0000\n",
            "Epoch 124: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 7.7389e-04 - accuracy: 1.0000 - val_loss: 1.4251e-05 - val_accuracy: 1.0000\n",
            "Epoch 125/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 125: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4854e-05 - val_accuracy: 1.0000\n",
            "Epoch 126/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 126: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 8.4753e-04 - accuracy: 1.0000 - val_loss: 1.7513e-05 - val_accuracy: 1.0000\n",
            "Epoch 127/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 9.0236e-04 - accuracy: 1.0000\n",
            "Epoch 127: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 9.5989e-04 - accuracy: 1.0000 - val_loss: 2.1689e-05 - val_accuracy: 1.0000\n",
            "Epoch 128/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 7.1228e-04 - accuracy: 1.0000\n",
            "Epoch 128: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 6.5825e-04 - accuracy: 1.0000 - val_loss: 2.5359e-05 - val_accuracy: 1.0000\n",
            "Epoch 129/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 6.6568e-04 - accuracy: 1.0000\n",
            "Epoch 129: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 6.6495e-04 - accuracy: 1.0000 - val_loss: 2.8194e-05 - val_accuracy: 1.0000\n",
            "Epoch 130/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 130: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.8405e-05 - val_accuracy: 1.0000\n",
            "Epoch 131/1000\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 131: saving model to .\\gesture_classifier.keras\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5746e-05 - val_accuracy: 1.0000\n",
            "Epoch 131: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1ff0ae03730>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=1000,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    callbacks=[cp_callback, es_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1074e-05 - accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WirBl-JE9hE3",
        "outputId": "71b30ca2-8294-4d9d-8aa2-800d90d399de",
        "scrolled": true,
        "tags": [
          "outputPrepend"
        ]
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 81ms/step\n",
            "[9.9998331e-01 1.6655025e-05]\n",
            "0\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# Inference test\n",
        "predict_result = model.predict(np.array([X_test[0]]))\n",
        "print(np.squeeze(predict_result))\n",
        "print(np.argmax(np.squeeze(predict_result)))\n",
        "print(y_test[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3U4yNWx9hE4"
      },
      "source": [
        "# Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "AP1V6SCk9hE5",
        "outputId": "08e41a80-7a4a-4619-8125-ecc371368d19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        49\n",
            "           1       1.00      1.00      1.00        50\n",
            "\n",
            "    accuracy                           1.00        99\n",
            "   macro avg       1.00      1.00      1.00        99\n",
            "weighted avg       1.00      1.00      1.00        99\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def print_confusion_matrix(y_true, y_pred, report=True):\n",
        "    labels = sorted(list(set(y_true)))\n",
        "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "    \n",
        "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
        " \n",
        "    fig, ax = plt.subplots(figsize=(7, 6))\n",
        "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
        "    ax.set_ylim(len(set(y_true)), 0)\n",
        "    plt.show()\n",
        "    \n",
        "    if report:\n",
        "        print('Classification Report')\n",
        "        print(classification_report(y_test, y_pred))\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print_confusion_matrix(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNP6aqzc9hE5"
      },
      "source": [
        "# Convert to model for Tensorflow-Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ODjnYyld9hE6"
      },
      "outputs": [],
      "source": [
        "# Save as a model dedicated to inference\n",
        "model.save(model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\zeins\\AppData\\Local\\Temp\\tmps7huuj6c\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\zeins\\AppData\\Local\\Temp\\tmps7huuj6c\\assets\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "368496"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_quantized_model = converter.convert()\n",
        "\n",
        "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get I / O tensor\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 1.]\n",
            "1\n",
            "CPU times: total: 0 ns\n",
            "Wall time: 1.1 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Inference implementation\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(np.squeeze(tflite_results))\n",
        "print(np.argmax(np.squeeze(tflite_results)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "keypoint_classification_EN.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "85b733480cc67b8cf4f7b44ea859236688838663f0d4c864dc5b1de551a5e467"
    },
    "kernelspec": {
      "display_name": "Python 3.9.4 64-bit ('mpenv': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
